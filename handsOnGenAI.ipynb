{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c0312e-b9d4-458c-a305-1d204cb0fdcd",
   "metadata": {},
   "source": [
    "# Hands-on: Getting Started with Generative AI APIs\n",
    "### by Mike Wolfson\n",
    "### **Phoenix Mobile & Emerging Technology** - 2/15/24\n",
    "### **DevFest Vancouver** - 11/18/2023\n",
    "### **DevFest Waterloo** - 10/21/2023\n",
    "\n",
    "In this hands-on workshop, participants will learn how to develop generative AI projects, harnessing the power of Jupyter Notebook. We'll demystify the foundations of generative AI, and get our hands dirty with real-time experiments. Whether you're a budding data scientist, or just intrigued by this emerging technology, join us as we unravel the potential of generative AI, one API call at a time. Prepare to leave with the knowledge, experience, and tools to craft your own generative masterpieces!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5ba03",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "```\n",
    "Python's simplicity, extensive libraries, community support, and versatility make it an ideal choice for AI development. It provides the tools and resources necessary to build AI models, work with data, and deploy AI solutions in a wide range of applications.\n",
    "```\n",
    "\n",
    "Download and Install Python [Site](https://www.python.org/downloads/)\n",
    "\n",
    "Official Documentation [Site](https://docs.python.org/3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bca17",
   "metadata": {},
   "source": [
    "## PIP\n",
    "\n",
    "**Pythons Package Manager** is now installed \n",
    "\n",
    "*We will be using this to download and install all of our project dependencies*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e2bce",
   "metadata": {},
   "source": [
    "## Jupyter Notebook\n",
    "\n",
    "- Introduction to Jupyter Notebooks.\n",
    "- Benefits of using Jupyter for interactive development.\n",
    "- Understanding cells, outputs, and extensions.\n",
    "\n",
    "[Jupyter Documentation](https://docs.jupyter.org/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0b3f2",
   "metadata": {},
   "source": [
    "### PIP Install\n",
    "\n",
    " `pip install jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a388c",
   "metadata": {},
   "source": [
    "#### Once you have this package installed, navigate to the location on your file-system where you want to store your notebook file, and then enter the following command on the command-line to start the jupyter environment\n",
    "\n",
    "`jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2263f9c",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers API\n",
    "\n",
    "PIP Install: \n",
    "\n",
    "`pip install transformers torch`\n",
    "\n",
    "Documentation: [Install Instructions](https://huggingface.co/docs/transformers)\n",
    "\n",
    "## Note\n",
    "\n",
    "> This Step is intended to validate the successful installation of Python and jupyter **without requiring an API key**, which is needed in the next steps.\n",
    "\n",
    "**You may want to skip this step** beacuse it downloads a large binary to your machine. If you intend to continue this workshop, you can skip directly to the \"Working with Google APIs\" section, where you will validate these your *python* and *jupyter* tool installations anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423f480",
   "metadata": {},
   "source": [
    "### generate_text_huggingface: helper function\n",
    "\n",
    "Use this to execute calls to the Hugging Face Transformers API\n",
    "\n",
    "*No API Key needed!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d50226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_text_huggingface(prompt, model_name=\"gpt2-medium\"):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, temperature=1.0)\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677064ef",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **Hugging Face Helper Function**\n",
    "\n",
    "Note: You will see an error when running this cell.  You can safely ignore:\n",
    "\n",
    "> The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
    "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
    "\n",
    "As long as you see that the output shows \"Once upon a time...\" with a lot more text, then this step is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text_huggingface(\"Once upon a time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e564a8",
   "metadata": {},
   "source": [
    "## Working with Google APIs\n",
    "\n",
    "```\n",
    "Large Language Models (LLMs) are a powerful, versatile type of machine learning model that enables computers to comprehend and generate natural language better than ever. They can be used to build all sorts of applications, from chat bots to virtual assistants to translation apps and much more. Plus, you don't have to be an AI expert or even write code to use them. All it takes are a few sentences or “prompts” to get started designing your own custom LLM app.\n",
    "```\n",
    "\n",
    "### Use **PIP** to Install Dependencies \n",
    "\n",
    "- Google GenerativeAI Python Library - `pip install -q google.generativeai`\n",
    "- Tools to grab API key from Environment variable: `pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd94e9e",
   "metadata": {},
   "source": [
    "## Enable Gemini Services and get API Key\n",
    "\n",
    "Get an API key by going here: [https://ai.google.dev/](https://ai.google.dev/)\n",
    "\n",
    "Note: \n",
    "> If you have an existing Google Cloud API key, you can use it, but you will need to enable to the API in the Google Cloud Console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fde748",
   "metadata": {},
   "source": [
    "### Working with API keys\n",
    "\n",
    "You will need to set the Gemini API key as a system variable named: `GOOGLE_API_KEY`.  \n",
    "\n",
    "- [Setting an Environment Variable on Mac/Linux](https://phoenixnap.com/kb/set-environment-variable-mac)\n",
    "- [Setting an Environment Variable on Windows](https://phoenixnap.com/kb/windows-set-environment-variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85524dc3",
   "metadata": {},
   "source": [
    "#### Import GenerativeAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27165c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "apiKey = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key=apiKey,\n",
    "               transport=\"rest\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20290bb8",
   "metadata": {},
   "source": [
    "## Explore the Available Models\n",
    "\n",
    "Validate the library has been imported correctly by exploring available models.\n",
    "\n",
    "> Successful output from this step validates successful setup of Google Generative AI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f805008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "    print(f\"name: {m.name}\")\n",
    "    print(f\"description: {m.description}\")\n",
    "    print(f\"generation methods:{m.supported_generation_methods}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e486139",
   "metadata": {},
   "source": [
    "### Filter models to ensure model we want is supported\n",
    "- `generateContent` is the value we are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d50897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb7fe8",
   "metadata": {},
   "source": [
    "Get a reference to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3b4ba",
   "metadata": {},
   "source": [
    "### generate_text_gemini: helper function to generate text\n",
    "\n",
    "- The `@retry` decorator helps you to retry the API call if it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8738a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text_gemini(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb2c16",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **Google GenAI Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = generate_text_gemini(\"Thursday evenings are perfect for\")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0bb07",
   "metadata": {},
   "source": [
    "## Working with the Open AI APIs\n",
    "\n",
    "```\n",
    "OpenAI's APIs offer developers the ability to integrate advanced artificial intelligence capabilities into their applications, enabling a wide range of tasks from text generation to complex problem-solving.\n",
    "```\n",
    "Documentation: [https://beta.openai.com/docs/](https://beta.openai.com/docs/)\n",
    "\n",
    "### Obtaining API Keys:\n",
    "- **OpenAI Platform**: [https://platform.openai.com/](https://platform.openai.com/)\n",
    "  - After signing up or logging in, navigate to the API section to manage and obtain your API keys.\n",
    "- You will need to set the OpenAI API key as a system variable named: `OPENAI_API_KEY`.  \n",
    "\n",
    "Note: do NOT check your API key into a public Github repo, or it will get revoked \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ecbad",
   "metadata": {},
   "source": [
    "### PIP Dependencies\n",
    "\n",
    "`pip install --upgrade openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17cf19-f3ee-4ccb-95fe-afbf2d592c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc3abf",
   "metadata": {},
   "source": [
    "### generate_text_openai: helper function to generate text from Open AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa30282-118b-499e-978e-39e832214847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_text_openai(pre, prompt, model=\"gpt-3.5-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": pre},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39685df4",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **Open AI Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text_openai(\"\", \"Thursday evenings are perfect for\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b08cb-9204-4713-93c4-521a60ac35b1",
   "metadata": {},
   "source": [
    "## Prompt template\n",
    "\n",
    "Using this simple template will help you organize your Prompts more effectively.\n",
    "\n",
    "- **system**: establishing context about what the quesiton is about (\"you are a pirate\")\n",
    "- **user**: what we are asking the GenAI to do (\"you are telling us your favorite joke about booty\")\n",
    "- **format**: formatting and other after-thoughts (\"use kid friendly language, and output the results in a json format\")\n",
    "\n",
    "I learned this prompt technique in the course \"[Pair Programming with a Large Language Model](https://www.deeplearning.ai/short-courses/pair-programming-llm/)\" - this is a short course by Laurence Moroney, and is a free course from [Deeplearning.ai](https://www.deeplearning.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7f846-fcfe-4965-a966-a22e04f50c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "{user}\n",
    "\n",
    "{format}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "You are a software engineer and you are at the Phoenix AI Developers meetup. You are excited because generative AI is so interesting.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f9461-e1d3-4a39-82c0-f0875b6e8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"\"\"\n",
    "tell me about the most interesting ways to get started developing using generative AI APIs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d04519-cb36-4f21-a780-11e4bd2a8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "format = \"\"\"\n",
    "mention the location and use flowery and descriptive language, and output the results as properly formatted markdown\n",
    "\"\"\"\n",
    "\n",
    "# format = \"\"\"\n",
    "# make sure to mention the location where you are and speak like a pirate, and output the results in a json format\n",
    "# \"\"\"\n",
    "\n",
    "# format = \"\"\"\n",
    "# use child friendly language, and output the results in a json format\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(user=user, format=format)\n",
    "print(generate_text_openai(system, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41cb9b-1e34-45ed-87b2-67465a964237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
