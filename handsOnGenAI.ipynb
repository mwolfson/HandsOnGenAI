{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c0312e-b9d4-458c-a305-1d204cb0fdcd",
   "metadata": {},
   "source": [
    "# Hands-on: Getting Started with Generative AI APIs\n",
    "### by Mike Wolfson\n",
    "### **DevFest Waterloo** - 10/21/2023\n",
    "\n",
    "In this hands-on workshop, participants will embark on a journey into the realm of generative AI, harnessing the power of Jupyter Notebook. We'll demystify the foundations of generative AI, and get our hands dirty with real-time experiments. Whether you're a budding data scientist, or just intrigued by this emerging technology, join us as we unravel the potential of generative AI, one API call at a time. Prepare to leave with the knowledge, experience, and tools to craft your own generative masterpieces!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5ba03",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "```\n",
    "Python's simplicity, extensive libraries, community support, and versatility make it an ideal choice for AI development. It provides the tools and resources necessary to build AI models, work with data, and deploy AI solutions in a wide range of applications.\n",
    "```\n",
    "\n",
    "Download and Install Python [Site](https://www.python.org/downloads/)\n",
    "\n",
    "Official Documentation [Site](https://docs.python.org/3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bca17",
   "metadata": {},
   "source": [
    "## PIP\n",
    "\n",
    "**Pythons Package Manager** is now installed \n",
    "\n",
    "*We will be using this to download and install all of our project dependencies*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e2bce",
   "metadata": {},
   "source": [
    "## Jupyter Notebook\n",
    "\n",
    "- Introduction to Jupyter Notebooks.\n",
    "- Benefits of using Jupyter for interactive development.\n",
    "- Understanding cells, outputs, and extensions.\n",
    "\n",
    "[Jupyter Documentation](https://docs.jupyter.org/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0b3f2",
   "metadata": {},
   "source": [
    "### PIP Install\n",
    "\n",
    " `pip install jupyter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2263f9c",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers API\n",
    "\n",
    "PIP Install: \n",
    "\n",
    "`pip install transformers torch`\n",
    "\n",
    "Documentation: [Install Instructions](https://huggingface.co/docs/transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423f480",
   "metadata": {},
   "source": [
    "### generate_text_huggingface: helper function\n",
    "\n",
    "Use this to execute calls to the Hugging Face Transformers API\n",
    "\n",
    "*No API Key needed!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d50226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_text_huggingface(prompt, model_name=\"gpt2-medium\"):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, temperature=1.0)\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677064ef",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **Hugging Face Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text_huggingface(\"Once upon a time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e564a8",
   "metadata": {},
   "source": [
    "## Working with the Google PaLM APIs\n",
    "\n",
    "```\n",
    "Large Language Models (LLMs) are a powerful, versatile type of machine learning model that enables computers to comprehend and generate natural language better than ever. They can be used to build all sorts of applications, from chat bots to virtual assistants to translation apps and much more. Plus, you don't have to be an AI expert or even write code to use them. All it takes are a few sentences or “prompts” to get started designing your own custom LLM app.\n",
    "```\n",
    "\n",
    "**PIP** - Install dependencies:\n",
    "\n",
    "`pip install -q google.generativeai`\n",
    "\n",
    "API key and documentation: [developers.generativeai.google](http://developers.generativeai.google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fde748",
   "metadata": {},
   "source": [
    "### Working with API keys\n",
    "\n",
    "You will need to set the PaLM API key as a system variable named: `GOOGLE_API_KEY`.  \n",
    "\n",
    "- [Setting an Environment Variable on Mac/Linux](https://phoenixnap.com/kb/set-environment-variable-mac)\n",
    "- [Setting an Environment Variable on Windows](https://phoenixnap.com/kb/windows-set-environment-variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd5cf1",
   "metadata": {},
   "source": [
    "PIP:\n",
    "\n",
    "`pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27165c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options as client_options_lib\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "apiKey = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "palm.configure(api_key=apiKey,\n",
    "               transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20290bb8",
   "metadata": {},
   "source": [
    "## Explore the Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f805008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in palm.list_models():\n",
    "    print(f\"name: {m.name}\")\n",
    "    print(f\"description: {m.description}\")\n",
    "    print(f\"generation methods:{m.supported_generation_methods}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e486139",
   "metadata": {},
   "source": [
    "### Filter models by their supported generation methods\n",
    "- `generateText` is currently recommended for coding-related prompts.\n",
    "- `generateMessage` is optimized for multi-turn chats (dialogues) with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d50897",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models()\n",
    "          if 'generateText'\n",
    "          in m.supported_generation_methods]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842057d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bison = models[0]\n",
    "model_bison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3b4ba",
   "metadata": {},
   "source": [
    "### generate_text_palm: helper function to generate text\n",
    "\n",
    "- The `@retry` decorator helps you to retry the API call if it fails.\n",
    "- We set the temperature to 0.0 so that the model returns the same output (completion) if given the same input (the prompt).)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8738a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text_palm(prompt,\n",
    "                  model=model_bison,\n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb2c16",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **PaLM Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = generate_text_palm(\"Saturdays are perfect for\")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0bb07",
   "metadata": {},
   "source": [
    "## Working with the Open AI APIs\n",
    "\n",
    "```\n",
    "OpenAI's APIs offer developers the ability to integrate advanced artificial intelligence capabilities into their applications, enabling a wide range of tasks from text generation to complex problem-solving.\n",
    "```\n",
    "Documentation: [https://beta.openai.com/docs/](https://beta.openai.com/docs/)\n",
    "\n",
    "### Obtaining API Keys:\n",
    "- **OpenAI Platform**: [https://platform.openai.com/](https://platform.openai.com/)\n",
    "  - After signing up or logging in, navigate to the API section to manage and obtain your API keys.\n",
    "- You will need to set the PaLM API key as a system variable named: `OPENAI_API_KEY`.  \n",
    "\n",
    "Note: do NOT check your API key into a public Github repo, or it will get revoked \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ecbad",
   "metadata": {},
   "source": [
    "### PIP Dependencies\n",
    "\n",
    "`pip install openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17cf19-f3ee-4ccb-95fe-afbf2d592c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc3abf",
   "metadata": {},
   "source": [
    "### generate_text_openai: helper function to generate text from Open AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa30282-118b-499e-978e-39e832214847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_openai(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39685df4",
   "metadata": {},
   "source": [
    "## Sending a prompt to the **Open AI Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text_openai(\"You are Igor the pirate\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b08cb-9204-4713-93c4-521a60ac35b1",
   "metadata": {},
   "source": [
    "## Prompt template\n",
    "\n",
    "Using this simple template will help you organize your Prompts more effectively.\n",
    "\n",
    "- pre: establishing context about what the quesiton is about (\"you are a pirate\")\n",
    "- question: what we are asking the GenAI to do (\"you are telling us your favorite joke about booty\")\n",
    "- post: formatting and other after-thoughts (\"use kid friendly language, and output the results in a json format\")\n",
    "\n",
    "I learned this prompt technique in the course \"[Pair Programming with a Large Language Model](https://www.deeplearning.ai/short-courses/pair-programming-llm/)\" - this is a short course by Laurence Moroney, and is a free course from [Deeplearning.ai](https://www.deeplearning.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7f846-fcfe-4965-a966-a22e04f50c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"s\n",
    "{pre}\n",
    "\n",
    "{question}\n",
    "\n",
    "{post}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = \"\"\"\n",
    "You are Igor the pirate.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f9461-e1d3-4a39-82c0-f0875b6e8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "tell us your favorite joke about booty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d04519-cb36-4f21-a780-11e4bd2a8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = \"\"\"\n",
    "use child friendly language, and output the results in a json format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(pre=pre, question=question, post=post)\n",
    "print(generate_text_openai(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
